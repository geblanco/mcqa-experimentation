vars:
  - ../../params/models.yaml
  - ../../params/data-disk.yaml
stages:
  classification:
    foreach: ${data}
    do:
      wdir: ../..
      cmd: export MLFLOW_TRACKING_URI="http://0.0.0.0:5000";
        mlflow run -e main . --no-conda
        -P classifier_dir=/data/gblanco/classification/${key}
        -P dataset=data/${item.data}
        -P params_file=params/classification-params.yaml
        -P classification_train_embeddings_path=${data-disk}/datasets/embeddings/${item.classification_train_embeddings}
        -P classification_eval_embeddings_path=${data-disk}/datasets/embeddings/${item.classification_eval_embeddings}
        -P classification_metrics_dir=data/metrics/classification/${key}
        -P corrections_embeddings_path=${data-disk}/datasets/embeddings/${item.corrections_embeddings}
        -P corrections_output_dir=data/metrics/model_corrections/${key}
        -P corrections_split=${item.corrections_split}
        -P corrections_strategy=${item.strategy}
        -P corrections_no_answer_text="${item.no_answer_text}"
        -P evaluation_nbest_predictions=data/metrics/model_corrections/${key}/${item.corrections_split_name}_nbest_predictions.json
        -P evaluation_split=${item.corrections_split}
        -P evaluation_output=data/metrics/model_corrections/${key}/scores.json
        -P evaluation_task=${item.task}
        -P evaluation_model_nbest_predictions=data/results/bert-train-${key}/${item.corrections_split_name}_nbest_predictions.json
        -P evaluation_model_output=data/metrics/bert-train-${key}/scores.json
        -P evaluation_utility_function="${item.utility_function}"
      deps:
        - data/${item.data}
        - src/etl/embeddings/classify/classification.py
        - src/etl/embeddings/transform/correct_predictions.py
      params:
        - params/classification-params.yaml:
            - features
            - classification
            - hyper-search
      # should add outputs and no cache?
